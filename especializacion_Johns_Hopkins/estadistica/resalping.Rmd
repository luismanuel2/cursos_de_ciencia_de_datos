---
title: "resalping"
author: "luis manuel"
date: "20/3/2021"
output: pdf_document
---

¡En esta lección, obtienes un bono! Hablaremos de dos temas en inferencia estadística, bootstrapping y pruebas de permutación. Ambos pertenecen a la categoría más amplia de métodos de remuestreo. Comenzaremos con bootstrapping.

El bootstrap es una herramienta útil para hacer inferencias estadísticas. Se utiliza para construir intervalos de confianza y calcular errores estándar para estadísticas que pueden ser difíciles por alguna razón (por ejemplo, falta de datos o sin formato cerrado). Wikipedia nos dice que el bootstrapping es una técnica que "permite estimar la distribución muestral de casi cualquier estadística utilizando métodos muy simples". Lo simple es bueno, ¿verdad?

La belleza del bootstrapping es que evita las matemáticas complicadas y, en su lugar, utiliza la simulación y el cálculo para inferir propiedades de distribución que de otro modo no podría determinar.

Es relativamente nuevo, desarrollado en 1979 por Bradley Efron, un estadístico de Stanford. El principio básico de bootstrap usa datos OBSERVADOS para construir una distribución de población ESTIMADA usando muestreo aleatorio con reemplazo. A partir de esta distribución (construida a partir de los datos observados) podemos estimar la distribución de la estadística que nos interesa.

En efecto, la muestra original observada sustituye a la población. Nuestros muestreos se convierten en observaciones a partir de las cuales estimamos una estadística y nos hacemos una idea de su distribución. Esto nos permite comprender mejor la población subyacente (de la que no teníamos suficientes datos).

He aquí un punto crítico. Al construir la distribución estimada, muestreamos los datos observados CON reemplazo. Si la muestra original tiene n de largo y muestreamos n veces sin reemplazo obtendriamos la muestra original permutada

El ejemplo motivador de las diapositivas implica calcular el promedio de 50 rollos de un dado. Por supuesto, podemos hacer esto teóricamente cuando sabemos que el dado es justo. Recuerde, E (x) = Suma (x * p (x)) para x = 1,2, ... 6 y p (x) = 1/6 para todos los valores de x.

Teóricamente, la media es de 3,5. Aquí, ejecutamos el código y trazamos un histograma después de tomar 1000 de esos promedios, cada uno de los 50 tirados de dados. Tenga en cuenta la inusual escala del eje y. Estamos mostrando esto como una función de densidad, por lo que el área de la región de color salmón es teóricamente 1. Con esta escala, sin embargo, todas las alturas de los contenedores suman 5. Por lo tanto, debe multiplicar cada altura por .2 y sume todos los resultados para obtener 1.

```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_1.png")
```

El punto es que lo empírico coincide con lo teórico. ¡Hurra! El contenedor más alto está centrado en 3.5 tal como lo predijeron las matemáticas. ¿Así que lo que?

¿Y si algún bromista quisiera que hicieras el mismo experimento con un dado que te dio y te advirtiera que los dados estaban cargados? En otras palabras, no fue justo. Tiene una distribución aleatoria como esta.

```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_2.png")
```
Los resultados no son igualmente probables, ¿verdad? Entonces, cuando haces tus 1000 tiradas de 50 rollos cada una, la densidad de los medios se ve diferente.

```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_3.png")
```

La imagen es un poco diferente, ¿verdad? Aunque este ejemplo es un poco artificial, ilustra un concepto importante. Realmente queremos una distribución de medias y solo tenemos un conjunto de observaciones. (En este caso fue la distribución empírica asociada con el dado injusto - el cuadro azul grande). Usamos esa distribución, para "crear" muchas (1000) distribuciones por muestreo con reemplazo de la dada. Tomamos muestras de 50000 veces, por lo que creamos 1000 distribuciones de 50 rollos cada una.

Luego calculamos la media de cada una de nuestras distribuciones creadas y obtuvimos una distribución de medias. El muestreo de una distribución muchas veces nos da cierta variabilidad en las estadísticas resultantes que calculamos. Luego podemos calcular el error estándar y los intervalos de confianza asociados con la estadística.

Recuerde los datos de altura de padre e hijo. Una vez más, lo hemos cargado. Hemos colocado la altura de los hijos en el vector sh y la longitud de este vector se almacena en la variable nh. Utilice el cabezal de comando R para ver las primeras entradas de sh.
```{r}
load("C:/Users/luism/Documents/sh.RData")
head(sh)
```

Ahora crearemos 1000 distribuciones de la misma longitud que el sh original. Haremos esto muestreando sh con reemplazo 1000 * nh veces y almacenaremos los resultados en una matriz con 1000 filas, cada una con nh entradas. Luego, tomaremos la mediana de cada fila y trazaremos el resultado.

Tenga en cuenta que cada vez que extraemos de la distribución empírica sh, es igualmente probable que se extraiga cada uno de sus nh puntos de datos, por lo que la probabilidad de extraer cualquiera es 1 / nh. Las 1000 muestras que creamos variarán del original.

Aquí está la curva de densidad resultante. Esto estima la distribución de medianas. La línea vertical gruesa muestra dónde se encuentra la mediana de los datos observados originales.
```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_3.png")
```

Almacenamos las 1000 medianas de los conjuntos remuestreados en el vector remuestreadoMedians. Use la función R mediana para calcular la mediana de números en este vector

```{r}
load("C:/Users/luism/Documents/rme.RData")
median(resampledMedians)
median(sh)
```

Bastante cerca, ¿verdad? Ahora volvamos a la teoría. Suponga que tiene una estadística que estima algún parámetro de población, pero no conoce su distribución muestral. El principio de arranque utiliza la distribución definida por los datos observados para aproximar la distribución muestral de esa estadística.

Lo bueno del bootstrapping es que siempre puedes hacerlo con simulación. El procedimiento general sigue primero simulando B conjuntos de datos completos a partir de los datos observados mediante muestreo con reemplazo. Asegúrese de que B sea grande y de que esté muestreando CON reemplazo para crear conjuntos de datos del mismo tamaño que el original.

Esto se aproxima a partir de la distribución muestral de esa estadística, al menos así como los datos se aproximan a la verdadera distribución de la población. Al calcular la estadística para cada conjunto de datos simulados y usar estas estadísticas simuladas, podemos definir un intervalo de confianza (por ejemplo, encontrar los percentiles 2.5 y 97.5) o tomar la desviación estándar para estimar un error estándar de esa estadística.

Tenga en cuenta que este proceso no utiliza ninguna matemática sofisticada o asintótica. El único supuesto detrás de esto es que la muestra observada es representativa de la población subyacente.

Hemos creado el vector fh para usted, que contiene las alturas de los padres a partir de los datos de padre e hijo con los que hemos estado trabajando. Tiene la misma longitud que los datos de los hijos (1078) que se almacenan en nh. B, el número de bootstraps que queremos se ha establecido en 1000. Ahora haremos un ejemplo en pequeños pasos.

Nuestra única muestra de datos observados está en el vector fh. Utilice el ejemplo de función R para muestrear fh nh * B veces. Establezca el reemplazo de argumento en VERDADERO. Ponga el resultado en la variable sam.
```{r}
load("C:/Users/luism/Documents/fh.RData")
nh<-1078
B<-1000
sam <- sample(fh,nh*B,replace=TRUE)
resam <- matrix(sam,B,nh)
```

Ahora use la función R aplicar para tomar la mediana (tercer argumento) de cada fila de resam (primer argumento). Pon el resultado en medicamentos. El segundo argumento, el número 1, especifica que la aplicación de la función es a las filas del primer argumento.

```{r}
meds <- apply(resam,1,median)
median(meds)-median(fh)
sd(meds)
```

Anteriormente hicimos este mismo proceso para los datos de los hijos y almacenamos las medianas remuestreadas en el vector de 1000 longitudes remuestreadasMedians. Encuentre el error estándar de medianos remuestreados.

Ahora encontraremos un intervalo de confianza del 95% para los datos de los hijos con el cuantil de la función R. El primer argumento es el vector de medianos remuestreados y el segundo es la expresión c (.025, .975). Hacerlo ahora.

```{r}
quantile(resampledMedians,c(.025,.975))
```
Cuantiles bastante cercanos, ¿verdad? Ahora haga lo mismo con los datos de los padres. Recuerde que está almacenado en los medicamentos vectoriales.

```{r}
quantile(meds,c(.025,.975))
```

Otro par de cuantiles cercanos, pero observe que estos cuantiles de las medianas de los padres difieren de las de los hijos.

Bootstrapping es un tema muy diverso y complicado y acabamos de echar un vistazo a la superficie aquí. La técnica que le mostramos no es paramétrica, es decir, no se basa en ninguna familia paramétrica de distribuciones de probabilidad. Usamos solo un conjunto de observaciones que supusimos que eran representativas de la población.

Por último, es posible que los intervalos de confianza que calculamos no funcionen muy bien debido a sesgos, pero el bootstrap del paquete R proporciona una solución fácil para este problema.

Ahora, a las pruebas de permutación, otra herramienta útil que se utiliza en las comparaciones de grupos. Como lo hizo el bootstrapping, las pruebas de permutación muestrean un solo conjunto de datos un trillón de veces y calculan una estadística basada en estos muestreos.

Las pruebas de permutación, sin embargo, se basan en la idea de intercambiabilidad de etiquetas de grupo. Mide si los resultados son independientes de la identidad del grupo o no. Nuestras infinidad de muestras simplemente permutan las etiquetas de grupo asociadas con los resultados. Veremos un ejemplo de esto.

Aquí hay una imagen del conjunto de datos InsectSprays que contiene recuentos de la cantidad de insectos muertos por seis aerosoles diferentes.
```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_5.png")
```

Usaremos la prueba de permutación para comparar el Spray B con el Spray C.

```{r}
load("C:/Users/luism/Documents/ins.RData")
load("C:/Users/luism/Documents/bdat.RData")
load("C:/Users/luism/Documents/cdat.RData")
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)

```
Por los rangos (así como por la imagen), los aerosoles se ven muy diferentes. Probaremos la hipótesis nula (obviamente falsa) de que sus medias son las mismas.
```{r}
load("C:/Users/luism/Documents/gr.RData")
BCcounts<-InsectSprays$count
```

También hemos definido para usted una función testStat de una línea que toma dos parámetros, una matriz de conteos y una matriz de identificadores asociados. Supone que todos los recuentos provienen del grupo B o del grupo C. Resta la media de los recuentos del grupo C de la media de los recuentos del grupo B. Escriba testStat sin paréntesis ni argumentos para ver cómo se define.
```{r}
testStat
```

Ahora establezca una variable obs invocando testStat con los argumentos BCcounts y group y asignando el resultado a obs. grupo y asignando el resultado a obs.
```{r}
obs <- testStat(BCcounts,group)
obs
```

Diferencia bastante grande, ¿verdad? Puede verificar esto usando:

```{r}
mean(Bdata$count)-mean(Cdata$count)
```

Ahora aquí es donde la prueba de permutación comienza a involucrar el remuestreo. Vamos a probar si la asociación de grupo particular de los recuentos afecta o no la diferencia de las medias.

Mantendremos la misma matriz de recuentos, simplemente los volveremos a etiquetar al azar, permutando la matriz de grupo. R hace que este proceso sea muy fácil. Llamar a la función sample (que hemos usado varias veces en esta lección) con un argumento, un nombre de matriz, simplemente permutará los elementos de esa matriz.

```{r}
sample(group)
```

Las etiquetas están todas mezcladas ahora. Haremos esta permutación de etiquetas y luego recalcularemos la diferencia de las medias de los dos grupos "nuevos" (realmente recién etiquetados).

Volveremos a etiquetar y calcularemos la diferencia de medias 10000 veces y almacenaremos las diferencias (de medias) en los permisos de la matriz.
```{r}
 mean(perms>obs)
```

Entonces, en promedio, 0 de las permutaciones tuvieron una diferencia mayor que la observada. Eso significa que rechazaríamos la hipótesis nula de que las medias de las dos pulverizaciones fueran iguales.

Aquí hay un histograma de la diferencia de medias. Parece bastante normal, ¿verdad? Podemos ver que la distribución va aproximadamente entre -10 y +10 y está centrada alrededor de 0. La línea vertical muestra dónde estaba la diferencia de medias observada y vemos que está bastante lejos de la distribución de las permutaciones remuestreadas. Esto significa que la identificación del grupo sí importaba y los aerosoles B y C eran bastante diferentes.
```{r ,echo=FALSE,fig.cap="A caption",out.width='100%'} 
knitr::include_graphics("C:/Users/luism/Documents/resal_6.png")
```

Aquí está la imagen de InsectSprays nuevamente. Supongamos que realizamos el mismo experimento, esta vez comparando los aerosoles D y E, que se parecen más. Hemos redefinido testStat para observar estos aerosoles y restar la media del aerosol E de la media del aerosol D.

También hemos almacenado los datos D y E en DEcounts y las etiquetas de grupo en grupo. Ejecute testStat ahora con DEcounts y group.
```{r}
testStat(DEcounts,group)
obs<-1.416667

```
Hemos almacenado este valor, 1.416667, en la variable obs para usted. Ahora ejecute el comando de permutación, con DEcounts.
```{r}
 perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
```

Finalmente, podemos graficar el histograma de la distribución de la diferencia de medias. Vemos que con estos aerosoles la diferencia de medias observada (la línea vertical) está más cerca de la media de las etiquetas permutadas. Esto indica que los aerosoles D y E son bastante similares y no rechazamos la hipótesis nula de que las medias eran iguales.
```{r}
knitr::include_graphics("C:/Users/luism/Documents/resal_6.png")
```

